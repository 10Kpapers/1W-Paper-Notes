# 一万篇论文笔记计划
[[1] Blockwise Parallel Decoding: 一种加速LLM解码的并行方法](https://zhuanlan.zhihu.com/p/652823496)

[[2] Contrastive Decoding: 一种可提高文本生成质量的解码方法](https://zhuanlan.zhihu.com/p/653387559)

[[3] contrastive search: 一种提高文本生成质量的解码方法](https://zhuanlan.zhihu.com/p/653450352)

[[4] LXMERT: Learning Cross-Modality Encoder Representations from Transformers](https://zhuanlan.zhihu.com/p/653964820)

[[5] SimVLM: 图片和文本拼接成prompt做Language Model训练](https://zhuanlan.zhihu.com/p/654050155)

[[6] CoCa: 在图生文过程中加入对比学习](https://zhuanlan.zhihu.com/p/654161055)

[[7] DiffSTG: 将扩散模型用于处理时空数据](https://zhuanlan.zhihu.com/p/656236507)

[[8] MolCLR: 基于GNN 的分子图表征对比学习框架](https://zhuanlan.zhihu.com/p/656769732)

[[9] CLIP4Clip: 利用 CLIP 做视频-文本检索](https://zhuanlan.zhihu.com/p/656811444)

[[10] CenterCLIP: 利用聚类算法提高文本-视频检索的效率](https://zhuanlan.zhihu.com/p/656811473)

[[11] Scaling Laws for Neural Machine Translation](https://zhuanlan.zhihu.com/p/656888149)

[[12] DocRED: 一个大规模文档级关系抽取数据集](https://zhuanlan.zhihu.com/p/656964531)

[[13] DocuNet: 把文档级关系抽取看作语义分割任务](https://zhuanlan.zhihu.com/p/656975670)

[[14] Segmenter: 用Transformer 做语义分割](https://zhuanlan.zhihu.com/p/657294681)

[[15] Swin Transformer: 一种层级 ViT 模型](https://zhuanlan.zhihu.com/p/657359846)

[[16] VALOR: Vision-Audio-Language三模态模型和数据集](https://zhuanlan.zhihu.com/p/657414556)

[[17] Multimodal Transformer: 多模态的院内死亡风险预测模型](https://zhuanlan.zhihu.com/p/657414912)

[[18] HiTANet: 层级Time-Aware Attention Networks做疾病风险预测](https://zhuanlan.zhihu.com/p/657543094)

[[19] TranSalNet: 融合 CNN+Transformer 做视觉显著性预测](https://zhuanlan.zhihu.com/p/657415194)

[[20] TransUNet: 将Transformer Encoder 融入 U-Net 做医学图像分割](https://zhuanlan.zhihu.com/p/657901979)

[[21] Swin-Unet: 只用Swin Transformer构建Unet 结构做医学图像分割](https://zhuanlan.zhihu.com/p/657910667)

[[22] iGPT: Generative Pretraining from Pixels](https://zhuanlan.zhihu.com/p/657963444)

[[23] 如何对 CLIP 进行 fine-tuning？](https://zhuanlan.zhihu.com/p/658645438)

[[24] ELMo: 生不逢时的动态词向量](https://zhuanlan.zhihu.com/p/658709277)

[[25] DeepWalk: Random Walk + word2vec 学习图节点向量表示](https://zhuanlan.zhihu.com/p/658938347)

[[26] Science BERT: 使用论文数据预训练的 BERT 模型](https://zhuanlan.zhihu.com/p/659205938)

[[27] BioBERT: 生物医学领域自己的 BERT 模型](https://zhuanlan.zhihu.com/p/659209593)

[[28] Clinical BERT: 使用 MIMIC 数据集继续训练 BERT 模型](https://zhuanlan.zhihu.com/p/659607514)

[[29] 不要停，继续预训练](https://zhuanlan.zhihu.com/p/659609320)

[[30] node2vec=skip-gram+bfs+dfs](https://zhuanlan.zhihu.com/p/658731335)

[[31] Non-local: 注意力机制的一种形态](https://zhuanlan.zhihu.com/p/660116933)

[[32] START: 自监督轨迹表示学习框架](https://zhuanlan.zhihu.com/p/660304153)

[[33] 线性复杂度的高效注意力机制：矩阵乘法的交换律](https://zhuanlan.zhihu.com/p/656944206)

[[重读经典, 常读常新][35] 注意力机制在 NLP 领域的诞生](https://zhuanlan.zhihu.com/p/660922705)

[[重读经典，常读常新][36]注意力机制在 NLP 领域的诞生 2](https://zhuanlan.zhihu.com/p/660955612)

[[37] 自注意力机制启蒙：用于句子编码](https://zhuanlan.zhihu.com/p/661013687)

[[重读经典，常读常新][38] Transformer: Attention Is All You Need](https://zhuanlan.zhihu.com/p/661228490)

[[39] LERT: 语言学信息增强的**中文**预训练模型](https://zhuanlan.zhihu.com/p/664200148)

[[40] GAT: GCN + Self-Attention](https://zhuanlan.zhihu.com/p/664316204)

[[41] CA-MSER: 多模态语音情感识别](https://zhuanlan.zhihu.com/p/664350153)

[[42] GraphSAGE: 基于特征的节点向量(图表示)学习方法](https://zhuanlan.zhihu.com/p/664524290)

[[43] Tail-GNN: 提升 graph 中尾节点向量的质量](https://zhuanlan.zhihu.com/p/664631713)

[[44] E-GAN: 用演化算法训练 GAN 模型](https://zhuanlan.zhihu.com/p/664665262)

[[45] HAN: 层级注意力模型用于篇章分类](https://zhuanlan.zhihu.com/p/664713316)

[[46] MO-EGAN: 用多目标演化算法训练GAN](https://zhuanlan.zhihu.com/p/665040587)

[[47] DiffDock:用扩散模型解决分子对接任务](https://zhuanlan.zhihu.com/p/665191390)

[[48] K-EmoCon: 自然对话场景下采集的情感识别数据集](https://zhuanlan.zhihu.com/p/665276718)


